"""
Episode data processor for enrichment pipeline.
Extracts and formats episode data programmatically.
Performance: ~0.1 seconds vs 5+ seconds for AI processing.
"""

from typing import List, Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class EpisodeProcessor:
    """
    Processes episode data from API responses.
    Deterministic field extraction and formatting.
    """
    
    # Fields to extract from episode data
    EPISODE_FIELDS = [
        'url',
        'title',
        'title_japanese',
        'title_romaji',
        'aired',
        'score',
        'filler',
        'recap',
        'duration',
        'synopsis'
    ]
    
    def process_episodes(self, episodes_data: List[Dict]) -> List[Dict]:
        """
        Process raw episode data from APIs.
        
        Args:
            episodes_data: Raw episode data from Jikan or other APIs
            
        Returns:
            Processed episode list with standardized fields
            
        Performance: ~0.1 seconds for 1000+ episodes
        """
        if not episodes_data:
            return []
        
        processed = []
        
        for episode in episodes_data:
            try:
                processed_episode = self._extract_episode_fields(episode)
                if processed_episode:
                    processed.append(processed_episode)
            except Exception as e:
                logger.warning(f"Failed to process episode: {e}")
                continue
        
        logger.debug(f"Processed {len(processed)}/{len(episodes_data)} episodes")
        return processed
    
    def _extract_episode_fields(self, episode: Dict) -> Optional[Dict[str, Any]]:
        """
        Extract specific fields from episode data.
        
        Args:
            episode: Raw episode data
            
        Returns:
            Processed episode with selected fields
        """
        processed = {}
        
        for field in self.EPISODE_FIELDS:
            if field in episode:
                value = episode[field]
                # Clean up null/empty values
                if value is not None and value != "":
                    processed[field] = value
        
        # Add episode number if available
        if 'mal_id' in episode:
            processed['episode_number'] = episode['mal_id']
        elif 'episode' in episode:
            processed['episode_number'] = episode['episode']
        
        return processed if processed else None
    
    def merge_episode_sources(self, *episode_sources: List[Dict]) -> List[Dict]:
        """
        Merge episode data from multiple API sources.
        
        Args:
            episode_sources: Multiple episode lists from different APIs
            
        Returns:
            Merged and deduplicated episode list
        """
        # Create a map by episode number
        episode_map = {}
        
        for source in episode_sources:
            if not source:
                continue
                
            for episode in source:
                ep_num = episode.get('episode_number')
                if not ep_num:
                    continue
                
                if ep_num not in episode_map:
                    episode_map[ep_num] = episode
                else:
                    # Merge data, preferring non-null values
                    episode_map[ep_num] = self._merge_episode_data(
                        episode_map[ep_num], 
                        episode
                    )
        
        # Sort by episode number and return
        sorted_episodes = sorted(
            episode_map.values(), 
            key=lambda x: x.get('episode_number', 0)
        )
        
        return sorted_episodes
    
    def _merge_episode_data(self, existing: Dict, new: Dict) -> Dict:
        """
        Merge two episode data dictionaries.
        
        Args:
            existing: Existing episode data
            new: New episode data to merge
            
        Returns:
            Merged episode data
        """
        merged = existing.copy()
        
        for key, value in new.items():
            # Prefer non-null, non-empty values
            if value is not None and value != "":
                # If existing value is null/empty, use new value
                if key not in merged or merged[key] is None or merged[key] == "":
                    merged[key] = value
                # For scores, prefer higher confidence (more reviews)
                elif key == 'score' and isinstance(value, (int, float)):
                    if value > 0:  # Only use positive scores
                        merged[key] = value
        
        return merged
    
    def validate_episode_data(self, episodes: List[Dict]) -> List[Dict]:
        """
        Validate and clean episode data.
        
        Args:
            episodes: Episode list to validate
            
        Returns:
            Validated episode list
        """
        validated = []
        
        for episode in episodes:
            # Must have at least episode number and one other field
            if not episode.get('episode_number'):
                continue
            
            # Remove empty fields
            cleaned = {
                k: v for k, v in episode.items() 
                if v is not None and v != ""
            }
            
            if len(cleaned) > 1:  # More than just episode number
                validated.append(cleaned)
        
        return validated
    
    def batch_process_episodes(
        self, 
        episodes: List[Dict], 
        batch_size: int = 50
    ) -> List[List[Dict]]:
        """
        Process episodes in batches for memory efficiency.
        
        Args:
            episodes: Full episode list
            batch_size: Size of each batch
            
        Returns:
            List of episode batches
        """
        if not episodes:
            return []
        
        batches = []
        for i in range(0, len(episodes), batch_size):
            batch = episodes[i:i + batch_size]
            processed_batch = self.process_episodes(batch)
            batches.append(processed_batch)
        
        return batches
    
    def extract_episode_statistics(self, episodes: List[Dict]) -> Dict:
        """
        Extract statistics from episode data.
        
        Args:
            episodes: Processed episode list
            
        Returns:
            Episode statistics
        """
        if not episodes:
            return {
                'total_episodes': 0,
                'has_fillers': False,
                'has_recaps': False,
                'average_score': None,
                'average_duration': None
            }
        
        total = len(episodes)
        fillers = sum(1 for ep in episodes if ep.get('filler'))
        recaps = sum(1 for ep in episodes if ep.get('recap'))
        
        # Calculate average score
        scores = [ep['score'] for ep in episodes if ep.get('score')]
        avg_score = sum(scores) / len(scores) if scores else None
        
        # Calculate average duration
        durations = [ep['duration'] for ep in episodes if ep.get('duration')]
        avg_duration = sum(durations) / len(durations) if durations else None
        
        return {
            'total_episodes': total,
            'filler_count': fillers,
            'recap_count': recaps,
            'has_fillers': fillers > 0,
            'has_recaps': recaps > 0,
            'average_score': round(avg_score, 2) if avg_score else None,
            'average_duration': round(avg_duration) if avg_duration else None
        }