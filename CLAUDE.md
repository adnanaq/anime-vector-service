# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## MANDATORY PROTOCOL ENFORCEMENT (ZERO TOLERANCE FOR VIOLATIONS)

### **üõë RULE VIOLATION = IMMEDIATE STOP + RULE CITATION**

### **VIOLATION PHRASE DETECTION (AUTO-STOP)**
**IF USER SAYS**: "skip the questions", "don't ask questions", "just implement", "no questions"
**MANDATORY RESPONSE**: 
```
üõë RULE VIOLATION DETECTED: BP-3 prohibits skipping clarification questions.
CLAUDE.md Rule BP-3 states: "NEVER start research or implementation without clarification"
I cannot proceed without clarification questions. This is non-negotiable.
```

### BP-1 (MUST): Mode Detection and Protocol Activation  
**BEFORE ANYTHING ELSE** - Detect mode and state protocol:
- Any broad optimization/improvement request = **@PLAN_MODE** (NOT @CODE_MODE)
- Specific implementation task = **@CODE_MODE**
- **ALWAYS** state: "Activating [X] protocol per CLAUDE.md rules"

### BP-2 (MUST): Context Loading Before Any Action
**IMMEDIATELY** after protocol activation, load context:
```
Loading required context per BP-2:
‚úì docs/architecture.md
‚úì docs/product_requirement_docs.md  
‚úì docs/technical.md
‚úì tasks/active_context.md
‚úì tasks/tasks_plan.md
```

### BP-3 (MUST): Clarification Questions - ZERO EXCEPTIONS
**SEQUENCE IS NON-NEGOTIABLE**: Context ‚Üí Questions ‚Üí Wait for Answers ‚Üí Then Proceed

**MANDATORY QUESTIONS** (cannot be skipped even if user requests):
1. **Specific Scope**: What exactly needs to be done?
2. **Priority/Urgency**: What's most critical?
3. **Constraints**: Timeline, resources, limitations?
4. **Success Criteria**: How do we measure success?
5. **Integration**: How should this fit with existing systems?

**ENFORCEMENT**: If user tries to skip questions, cite BP-3 and refuse to proceed

### BP-4 (MUST): Architecture Validation
**FOR ANY SYSTEM CHANGES** - validate against docs/architecture.md:
- Parse mermaid diagrams
- Check component boundaries
- **STOP** if violations detected

## Rules System - Compressed Protocols

### Mode Tokens (with mandatory validation)
- `@PLAN_MODE` ‚Üí **MUST** Load docs/ + tasks/ ‚Üí **MUST** Ask Clarification Questions ‚Üí Research ‚Üí Strategy ‚Üí Validate ‚Üí Document
- `@CODE_MODE` ‚Üí **MUST** Load context + src/ ‚Üí **MUST** Analyze deps ‚Üí Plan ‚Üí Simulate ‚Üí Test ‚Üí Document

### Protocol Tokens  
- `@PRE_IMPL` ‚Üí **MUST** Read docs/ + tasks/ + src/ context + dependency analysis + flow analysis
- `@ARCH_VALID` ‚Üí **MUST** Parse mermaid from docs/architecture.md ‚Üí validate ‚Üí **STOP** if violations
- `@SIM_TEST` ‚Üí **MUST** Dry run changes ‚Üí validate no breakage ‚Üí fix before implement
- `@MEM_UPDATE` ‚Üí **MUST** Review memory files ‚Üí update context ‚Üí document patterns

### Intelligence Tokens (AUTOMATICALLY ENFORCED)

### **üîç ANTI-PATTERN AUTO-DETECTION (IMMEDIATE STOP)**
**Trigger Phrases** ‚Üí **MANDATORY STOP RESPONSE**:
```
"optimize everything" ‚Üí üõë ANTI-PATTERN: Premature optimization detected per CLAUDE.md
"make it faster" ‚Üí üõë ANTI-PATTERN: Need specific bottlenecks and baselines first
"improve performance" ‚Üí üõë ANTI-PATTERN: Must identify specific performance issues
"fix all issues" ‚Üí üõë ANTI-PATTERN: Need issue prioritization and scope
```

### **‚ö†Ô∏è ERROR CONTEXT MANDATORY CHECK**
**ANY mention of**: "error", "failure", "broken", "not working", "failing"
**REQUIRED FIRST ACTION**: 
```
Checking @ERRORS per CLAUDE.md rules...
From rules/error-documentation.md: [list relevant known issues]
Applying known solutions before new investigation...
```

### **üìö LESSONS AUTO-APPLICATION**
**MUST apply patterns** from rules/lessons-learned.md for:
- Performance requests ‚Üí async-first, config-driven patterns
- Architecture changes ‚Üí graceful degradation principles  
- Implementation ‚Üí multi-vector design philosophy
- Error handling ‚Üí context-rich error messages

### **üîÑ SELF-UPDATE TRIGGERS**
- Pattern violations detected ‚Üí Update rules
- New successful patterns ‚Üí Document in lessons-learned
- Error resolutions ‚Üí Update error-documentation

### Execution Pattern (WITH VALIDATION GATES)
```
User Request ‚Üí Mode Detection (STATE EXPLICITLY) ‚Üí 
Load @[MODE]_MODE ‚Üí VALIDATE Context Loaded ‚Üí 
Apply @PRE_IMPL ‚Üí VALIDATE @ARCH_VALID ‚Üí 
Execute with @LESSONS + @ERRORS ‚Üí @SIM_TEST ‚Üí 
Implement ‚Üí @MEM_UPDATE
```

### üîí MANDATORY VALIDATION GATES (CANNOT BE BYPASSED)

**GATE 1: RULE VIOLATION DETECTION**
- [ ] ‚úã Check for "skip questions" phrases ‚Üí STOP if detected
- [ ] ‚úã Check for anti-pattern triggers ‚Üí STOP if detected  
- [ ] ‚úã Check for error mentions ‚Üí Check @ERRORS first

**GATE 2: PROTOCOL COMPLIANCE**
- [ ] üìã Protocol explicitly stated with CLAUDE.md reference
- [ ] üìã Context files loaded with checkmark confirmation
- [ ] üìã Clarification questions asked (MANDATORY - no exceptions)
- [ ] üìã User responses received before proceeding

**GATE 3: ARCHITECTURE VALIDATION** 
- [ ] üèóÔ∏è Architecture constraints checked against docs/architecture.md
- [ ] üèóÔ∏è Component boundaries validated
- [ ] üèóÔ∏è Interface contracts verified

### **üö® VIOLATION RESPONSE TEMPLATES**

**For "skip questions" violations:**
```
üõë RULE VIOLATION: BP-3 Clarification Questions cannot be skipped
CLAUDE.md states: "NEVER start implementation without clarification"
This is non-negotiable. I need answers to proceed safely.
```

**For anti-pattern violations:**
```
üõë ANTI-PATTERN DETECTED: [specific pattern]
Per CLAUDE.md rules, I must clarify requirements first.
[Specific questions for this anti-pattern]
```

**For missing context:**
```
üõë PROTOCOL VIOLATION: Context loading required per BP-2
Loading context files now...
```

**Usage**: Reference tokens trigger full protocol expansion. **IMPORTANT**: Rules are recursive - they apply at every step.

## Repository Overview

This is a specialized microservice for semantic search over anime content using vector embeddings and Qdrant database. The service provides text, image, and multimodal search capabilities with production-ready features including health checks, monitoring, and CORS support.

## Development Commands

### Local Development Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Start Qdrant database only
docker compose -f docker/docker-compose.yml up -d qdrant

# Run service locally for development
python -m src.main
```

### Docker Development (Recommended)
```bash
# Start full stack (service + database)
docker compose -f docker/docker-compose.yml up -d

# View logs
docker compose -f docker/docker-compose.yml logs -f vector-service

# Stop services
docker compose -f docker/docker-compose.yml down
```

### Testing and Quality
```bash
# Run tests
pytest

# Run specific test file
pytest test/test_filename.py

# Run tests with coverage
pytest --cov=src

# Code formatting
black src/
isort src/
autoflake --remove-all-unused-imports --in-place --recursive src/
```

### Service Health Checks
```bash
# Check service health
curl http://localhost:8002/health

# Check Qdrant health
curl http://localhost:6333/health

# Get database statistics
curl http://localhost:8002/api/v1/admin/stats
```

## Architecture Overview

### Core Architecture Pattern
The service follows a layered microservice architecture with clear separation of concerns:

**API Layer** (`src/api/`) ‚Üí **Processing Layer** (`src/vector/`) ‚Üí **Database Layer** (Qdrant)

### Key Architectural Components

#### 1. FastAPI Application (`src/main.py`)
- Async application with lifespan management
- Global Qdrant client initialization with health checks
- CORS middleware and structured logging
- Graceful startup/shutdown with dependency validation

#### 2. Configuration System (`src/config/settings.py`)
- Pydantic-based settings with environment variable support
- Comprehensive validation for all configuration parameters
- Support for multiple embedding providers and models
- Performance tuning parameters (quantization, HNSW, batch sizes)

#### 3. Multi-Vector Processing (`src/vector/`)
- **QdrantClient**: Advanced vector database operations with quantization support
- **TextProcessor**: BGE-M3 embeddings for semantic text search (384-dim)
- **VisionProcessor**: JinaCLIP v2 embeddings for image search (512-dim)
- **Fine-tuning modules**: Character recognition, art style classification, genre enhancement

#### 4. API Endpoints (`src/api/`)
- **Search Router**: Text, image, and multimodal search endpoints
- **Similarity Router**: Content-based and visual similarity operations
- **Admin Router**: Database management, statistics, and reindexing

#### 5. Data Enrichment Pipeline (`src/enrichment/`)
- **API Helpers**: Integration with 6+ external anime APIs (AniList, Kitsu, AniDB, etc.)
- **Scrapers**: Web scraping with Cloudflare bypass capabilities
- **Multi-stage AI Pipeline**: Modular prompt system for data enhancement

### Multi-Vector Collection Design
The service uses a single Qdrant collection with named vectors:
- `text`: 384-dimensional BGE-M3 embeddings for semantic search
- `picture`: 512-dimensional JinaCLIP v2 embeddings for cover art
- `thumbnail`: 512-dimensional JinaCLIP v2 embeddings for thumbnails

This design enables efficient multimodal search while maintaining data locality and reducing storage overhead.

### Configuration-Driven Model Selection
The service supports multiple embedding providers through configuration:
- **Text Models**: BGE-M3, BGE-small/base/large-v1.5, custom HuggingFace models
- **Vision Models**: JinaCLIP v2, CLIP ViT-B/32, SigLIP-384
- **Provider Flexibility**: Easy switching between embedding providers per modality

### Performance Optimization Features
- **Vector Quantization**: Binary/Scalar/Product quantization for 40x speedup potential
- **HNSW Tuning**: Optimized parameters for anime-specific search patterns
- **Payload Indexing**: Fast filtering on genre, year, type, status fields
- **Hybrid Search**: Single-request API for combined text+image queries
- **GPU Acceleration**: Support for GPU-accelerated model inference

## Environment Variables

### Critical Configuration
- `QDRANT_URL`: Vector database URL (default: http://localhost:6333)
- `QDRANT_COLLECTION_NAME`: Collection name (default: anime_database)
- `TEXT_EMBEDDING_MODEL`: Text model (default: BAAI/bge-m3)
- `IMAGE_EMBEDDING_MODEL`: Image model (default: jinaai/jina-clip-v2)

### Performance Tuning
- `QDRANT_ENABLE_QUANTIZATION`: Enable vector quantization (default: false)
- `QDRANT_QUANTIZATION_TYPE`: Quantization type (scalar, binary, product)
- `MODEL_WARM_UP`: Pre-load models during startup (default: false)
- `MAX_BATCH_SIZE`: Maximum batch size for operations (default: 500)

### Service Configuration
- `VECTOR_SERVICE_PORT`: Service port (default: 8002)
- `DEBUG`: Enable debug mode (default: true)
- `LOG_LEVEL`: Logging level (default: INFO)

## Memory Files System

This repository uses a comprehensive Memory Files system for project documentation. Always consult these files before making architectural changes or planning new features.

## Development Patterns

### Async-First Architecture
All I/O operations use async/await patterns. The service is designed for high concurrency with proper async context management.

### Configuration-Driven Features
Most functionality is configurable through environment variables rather than code changes. This enables zero-downtime configuration updates.

### Multi-Vector Design Philosophy
Named vectors in the same collection outperform separate collections for multi-modal data. This architecture provides 40% better search performance.

### Error Handling Strategy
The service implements graceful degradation - it continues operating with reduced functionality when dependencies fail rather than complete service failure.

## Integration Points

### External Dependencies
- **Qdrant Database**: Primary vector storage (required)
- **HuggingFace Models**: Text and image embeddings (cached locally)
- **External APIs**: Optional enrichment from anime platforms

### Client Integration
- Python client library available in `client/` directory
- REST API with comprehensive OpenAPI documentation at `/docs`
- Health check endpoint at `/health` for load balancer integration